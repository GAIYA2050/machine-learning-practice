决策树的一个重要任务是为了理解数据中所蕴含的知识信息，因此决策树可以使用不熟悉的数据集合，
并从中提取出一系列规则，这些机器根据数据集创建规则的过程，就是机器学习的过程。

决策树的优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征
数据；缺点：可能会产生过度匹配问题；适用数据类型：数值型和标称型。

构造决策树时需要解决的第一个问题就是：当前数据集上的哪个特征在划分数据分类时起决定性作用。
为了找到决定性的特征，划分出最好的结果，我们必须评估每个特征（特征评估的准则）。
创建分支的伪代码函数
createBranch()
检测数据集中的每个子项是否属于同一分类：
If so return 类标签
Else
    寻找划分数据集的最好特征
    划分数据集
    创建分支节点
        for 每个划分的子集
            调用函数createBranch并增加返回结果到分支节点中
return 分支节点

决策树的一般流程
（1）收集数据：可以使用任何方法。
（2）准备数据：树构造算法只适合于标称型数据，因此数值型数据必须离散化。
（3）分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
（4）训练算法：构造树的数据结构。
（5）测试算法：使用经验树计算错误率。
（6）使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的
     内在含义。
